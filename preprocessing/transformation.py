import pandas as pd
import glob
import os
from datetime import datetime

def aggregate_master_data():
    """
    Gá»™p táº¥t cáº£ file Ä‘Ã£ lÃ m sáº¡ch tá»« data/cleaned vÃ o thÆ° má»¥c data/master
    Thá»±c hiá»‡n deduplication vÃ  Ä‘áº£m báº£o schema nháº¥t quÃ¡n
    """
    CLEANED_FOLDER = 'data/cleaned'
    MASTER_FOLDER = 'data/master'
    
    # Tá»± Ä‘á»™ng táº¡o thÆ° má»¥c master náº¿u chÆ°a cÃ³
    os.makedirs(MASTER_FOLDER, exist_ok=True)
    
    # TÃ¬m táº¥t cáº£ cÃ¡c file Ä‘Ã£ lÃ m sáº¡ch (cÃ³ háº­u tá»‘ _cleaned_)
    all_cleaned_files = glob.glob(os.path.join(CLEANED_FOLDER, "*_cleaned_*.csv"))
    
    if not all_cleaned_files:
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u sáº¡ch nÃ o trong {CLEANED_FOLDER}!")
        print(f"   HÃ£y cháº¡y 'python preprocessing/cleaning.py' trÆ°á»›c.")
        return
    
    print(f"ğŸ”„ Báº¯t Ä‘áº§u tá»•ng há»£p {len(all_cleaned_files)} file dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch...")
    
    list_df = []
    for filename in all_cleaned_files:
        try:
            df = pd.read_csv(filename, encoding='utf-8-sig')
            
            # Kiá»ƒm tra schema
            required_cols = ['brand', 'model', 'year', 'price', 'mileage', 'fuel', 
                           'location', 'color', 'source', 'crawl_date']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                print(f"   âš ï¸ File {os.path.basename(filename)} thiáº¿u cá»™t: {missing_cols}")
                continue
            
            # Äáº£m báº£o kiá»ƒu dá»¯ liá»‡u Ä‘Ãºng
            df['price'] = pd.to_numeric(df['price'], errors='coerce').astype('Int64')
            df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')
            df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce').astype('Int64')
            
            # Loáº¡i bá» cÃ¡c dÃ²ng cÃ³ giÃ¡ trá»‹ null á»Ÿ cÃ¡c trÆ°á»ng quan trá»ng
            df = df.dropna(subset=['price', 'year'])
            
            list_df.append(df)
            print(f"   âœ… ÄÃ£ náº¡p: {os.path.basename(filename)} ({len(df):,} dÃ²ng)")
            
        except Exception as e:
            print(f"   âŒ Lá»—i khi Ä‘á»c {filename}: {e}")
    
    if not list_df:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u há»£p lá»‡ Ä‘á»ƒ tá»•ng há»£p.")
        return
    
    # Gá»™p táº¥t cáº£ DataFrames
    print(f"\nğŸ“Š Äang gá»™p {len(list_df)} file...")
    master_df = pd.concat(list_df, ignore_index=True)
    
    print(f"   -> Tá»•ng sá»‘ dÃ²ng trÆ°á»›c khi deduplication: {len(master_df):,}")
    
    # Loáº¡i bá» trÃ¹ng láº·p (Deduplication)
    # TrÃ¡nh trÆ°á»ng há»£p má»™t xe Ä‘Äƒng trÃªn nhiá»u trang web bá»‹ tÃ­nh trÃ¹ng
    # Sá»­ dá»¥ng brand, model, year, price, mileage Ä‘á»ƒ xÃ¡c Ä‘á»‹nh trÃ¹ng láº·p
    before_count = len(master_df)
    
    # LÃ m sáº¡ch dá»¯ liá»‡u trÆ°á»›c khi deduplication
    master_df['brand'] = master_df['brand'].str.strip()
    master_df['model'] = master_df['model'].str.strip()
    
    # Deduplication: loáº¡i bá» cÃ¡c dÃ²ng trÃ¹ng láº·p
    # Giá»¯ láº¡i dÃ²ng Ä‘áº§u tiÃªn khi cÃ³ trÃ¹ng
    master_df = master_df.drop_duplicates(
        subset=['brand', 'model', 'year', 'price', 'mileage'],
        keep='first'
    )
    
    after_count = len(master_df)
    removed_duplicates = before_count - after_count
    
    # Sáº¯p xáº¿p theo nÄƒm vÃ  giÃ¡ (Ä‘á»ƒ dá»… xem)
    master_df = master_df.sort_values(['year', 'price'], ascending=[False, True])
    
    # Reset index
    master_df = master_df.reset_index(drop=True)
    
    # Äáº£m báº£o cÃ¡c cá»™t theo Ä‘Ãºng thá»© tá»± schema
    schema_cols = ['brand', 'model', 'year', 'price', 'mileage', 'fuel', 
                  'location', 'color', 'source', 'crawl_date']
    master_df = master_df[schema_cols]
    
    # Äáº·t tÃªn file cÃ³ timestamp Ä‘á»ƒ phÃ¢n biá»‡t cÃ¡c láº§n tá»•ng há»£p
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    output_filename = f"master_dataset_all_{timestamp}.csv"
    output_path = os.path.join(MASTER_FOLDER, output_filename)
    
    # LÆ°u file vÃ o má»¥c master
    master_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    # --- THá»NG KÃŠ ---
    print("\n" + "="*60)
    print(f"âœ… Tá»”NG Há»¢P THÃ€NH CÃ”NG!")
    print(f"ğŸ“Š Sá»‘ lÆ°á»£ng ban Ä‘áº§u: {before_count:,} dÃ²ng")
    print(f"ğŸ§¹ ÄÃ£ loáº¡i bá» trÃ¹ng láº·p: {removed_duplicates:,} dÃ²ng")
    print(f"ğŸ“Š Sá»‘ lÆ°á»£ng sau khi deduplication: {after_count:,} dÃ²ng")
    print(f"ğŸ’¾ File lÆ°u táº¡i: {output_path}")
    print("="*60)
    
    # Thá»‘ng kÃª theo source
    print("\n--- THá»NG KÃŠ THEO NGUá»’N Dá»® LIá»†U ---")
    source_stats = master_df['source'].value_counts()
    print(source_stats.to_string())
    
    # Thá»‘ng kÃª theo brand (Top 10)
    print("\n--- THá»NG KÃŠ THEO HÃƒNG XE (Top 10) ---")
    brand_stats = master_df['brand'].value_counts().head(10)
    print(brand_stats.to_string())
    
    # Thá»‘ng kÃª theo nÄƒm
    print("\n--- THá»NG KÃŠ THEO NÄ‚M Sáº¢N XUáº¤T ---")
    year_stats = master_df['year'].value_counts().sort_index(ascending=False).head(10)
    print(year_stats.to_string())
    
    # Thá»‘ng kÃª giÃ¡
    print("\n--- THá»NG KÃŠ GIÃ XE ---")
    print(f"   GiÃ¡ tháº¥p nháº¥t: {master_df['price'].min():,} VNÄ")
    print(f"   GiÃ¡ cao nháº¥t: {master_df['price'].max():,} VNÄ")
    print(f"   GiÃ¡ trung bÃ¬nh: {master_df['price'].mean():,.0f} VNÄ")
    print(f"   GiÃ¡ trung vá»‹: {master_df['price'].median():,.0f} VNÄ")
    
    # Hiá»ƒn thá»‹ máº«u dá»¯ liá»‡u
    print("\n--- MáºªU Dá»® LIá»†U MASTER (10 dÃ²ng Ä‘áº§u) ---")
    print(master_df.head(10).to_string())


if __name__ == "__main__":
    aggregate_master_data()
