import pandas as pd
import glob
import os
from datetime import datetime
from sqlalchemy import create_engine, types

# ======================================================
# CONFIG
# ======================================================
CLEANED_FOLDER = "data/cleaned"
MASTER_FOLDER = "data/master"
DB_NAME = "car_project_db.sqlite"

REQUIRED_COLUMNS = [
    'brand', 'model', 'year', 'price', 'mileage',
    'fuel', 'location', 'color', 'source', 'crawl_date'
]

# ======================================================
# MAIN FUNCTION
# ======================================================
def aggregate_master_data():
    """
    Pipeline t·ªïng h·ª£p d·ªØ li·ªáu cu·ªëi:
    - ƒê·ªçc d·ªØ li·ªáu s·∫°ch
    - Validate schema
    - Chu·∫©n h√≥a d·ªØ li·ªáu
    - L·ªçc tr√πng, l·ªçc r√°c
    - T·∫°o ID
    - L∆∞u CSV + SQLite
    """

    os.makedirs(MASTER_FOLDER, exist_ok=True)

    # --------------------------------------------------
    # 1. LOAD FILE CLEANED
    # --------------------------------------------------
    cleaned_files = glob.glob(os.path.join(CLEANED_FOLDER, "*_cleaned_*.csv"))

    if not cleaned_files:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file cleaned trong {CLEANED_FOLDER}")
        return

    print(f"üîÑ ƒêang n·∫°p {len(cleaned_files)} file d·ªØ li·ªáu s·∫°ch...")

    dfs = []
    for file in cleaned_files:
        try:
            df = pd.read_csv(file, encoding="utf-8-sig")
            df.columns = df.columns.str.strip()

            # Validate schema
            missing_cols = set(REQUIRED_COLUMNS) - set(df.columns)
            if missing_cols:
                print(f"‚ùå B·ªè qua {os.path.basename(file)} (thi·∫øu c·ªôt {missing_cols})")
                continue

            # √âp ki·ªÉu d·ªØ li·ªáu
            df['price'] = pd.to_numeric(df['price'], errors='coerce')
            df['year'] = pd.to_numeric(df['year'], errors='coerce')
            df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce')

            # B·ªè d√≤ng thi·∫øu d·ªØ li·ªáu quan tr·ªçng
            df.dropna(subset=['brand', 'price', 'year'], inplace=True)

            dfs.append(df)
            print(f"   ‚úÖ {os.path.basename(file)}: {len(df):,} d√≤ng")

        except Exception as e:
            print(f"   ‚ùå L·ªói ƒë·ªçc {file}: {e}")

    if not dfs:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ t·ªïng h·ª£p.")
        return

    # --------------------------------------------------
    # 2. MERGE & DEDUPLICATION
    # --------------------------------------------------
    master_df = pd.concat(dfs, ignore_index=True)

    # Chu·∫©n h√≥a text
    for col in ['brand', 'model', 'fuel', 'color', 'location']:
        master_df[col] = master_df[col].astype(str).str.strip().str.title()

    # L·ªçc tr√πng
    before = len(master_df)
    master_df.drop_duplicates(
        subset=['brand', 'model', 'year', 'price', 'mileage'],
        keep='first',
        inplace=True
    )
    after = len(master_df)

    print(f"üßπ L·ªçc tr√πng: {before:,} ‚Üí {after:,}")

    # --------------------------------------------------
    # 3. DATA STANDARDIZATION
    # --------------------------------------------------
    # Chu·∫©n h√≥a nhi√™n li·ªáu
    fuel_map = {
        'XƒÉng': 'XƒÉng', 'Gasoline': 'XƒÉng', 'Petrol': 'XƒÉng',
        'D·∫ßu': 'D·∫ßu', 'Diesel': 'D·∫ßu',
        'ƒêi·ªán': 'ƒêi·ªán', 'Electric': 'ƒêi·ªán', 'Ev': 'ƒêi·ªán',
        'Hybrid': 'Hybrid', 'Lai': 'Hybrid'
    }
    master_df['fuel'] = master_df['fuel'].map(fuel_map).fillna(master_df['fuel'])

    # Chu·∫©n h√≥a m√†u
    def normalize_color(c):
        c = str(c).lower()
        if 'tr·∫Øng' in c: return 'Tr·∫Øng'
        if 'ƒëen' in c: return 'ƒêen'
        if 'ƒë·ªè' in c: return 'ƒê·ªè'
        if 'b·∫°c' in c: return 'B·∫°c'
        if 'x√°m' in c or 'ghi' in c: return 'X√°m'
        if 'xanh' in c: return 'Xanh'
        if 'n√¢u' in c: return 'N√¢u'
        if 'v√†ng' in c or 'c√°t' in c: return 'V√†ng'
        return 'Kh√°c'

    master_df['color_group'] = master_df['color'].apply(normalize_color)

    # L·ªçc outlier
    current_year = datetime.now().year
    master_df = master_df[
        (master_df['year'] >= 1990) &
        (master_df['year'] <= current_year + 1) &
        (master_df['price'] >= 20_000_000)
    ]

    # --------------------------------------------------
    # 4. SORT & CREATE ID
    # --------------------------------------------------
    master_df.sort_values(
        by=['year', 'price'],
        ascending=[False, True],
        inplace=True
    )
    master_df.reset_index(drop=True, inplace=True)

    master_df.insert(0, 'id', master_df.index + 1)

    # --------------------------------------------------
    # 5. SELECT FINAL COLUMNS
    # --------------------------------------------------
    final_columns = [
        'id', 'brand', 'model', 'year', 'price', 'mileage',
        'fuel', 'location', 'color', 'color_group',
        'source', 'url', 'crawl_date'
    ]
    final_columns = [c for c in final_columns if c in master_df.columns]
    master_df = master_df[final_columns]

    # --------------------------------------------------
    # 6. SAVE CSV
    # --------------------------------------------------
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    csv_path = os.path.join(
        MASTER_FOLDER,
        f"master_dataset_final_{timestamp}.csv"
    )
    master_df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"üíæ ƒê√£ l∆∞u CSV: {csv_path}")

    # --------------------------------------------------
    # 7. SAVE SQLITE
    # --------------------------------------------------
    db_path = os.path.join(MASTER_FOLDER, DB_NAME)
    engine = create_engine(f"sqlite:///{os.path.abspath(db_path)}")

    master_df.to_sql(
        'cars',
        con=engine,
        if_exists='replace',
        index=False,
        dtype={
            'id': types.Integer(),
            'price': types.BigInteger(),
            'year': types.Integer(),
            'mileage': types.Integer()
        }
    )

    print(f"üóÑÔ∏è  ƒê√£ l∆∞u SQLite DB: {db_path}")

    # --------------------------------------------------
    # 8. SUMMARY
    # --------------------------------------------------
    print("\n" + "=" * 60)
    print("‚úÖ HO√ÄN T·∫§T PIPELINE MASTER DATA")
    print(f"üìä T·ªïng s·ªë xe s·∫°ch: {len(master_df):,}")
    print("üîã Ph√¢n b·ªë nhi√™n li·ªáu:")
    print(master_df['fuel'].value_counts())
    print("=" * 60)


# ======================================================
# RUN
# ======================================================
if __name__ == "__main__":
    aggregate_master_data()
