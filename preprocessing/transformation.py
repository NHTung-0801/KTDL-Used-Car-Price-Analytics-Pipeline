import pandas as pd
import glob
import os
from datetime import datetime
<<<<<<< HEAD

def aggregate_master_data():
    """
    Gá»™p táº¥t cáº£ file Ä‘Ã£ lÃ m sáº¡ch tá»« data/cleaned vÃ o thÆ° má»¥c data/master
    Thá»±c hiá»‡n deduplication vÃ  Ä‘áº£m báº£o schema nháº¥t quÃ¡n
    """
    CLEANED_FOLDER = 'data/cleaned'
    MASTER_FOLDER = 'data/master'
    
    # Tá»± Ä‘á»™ng táº¡o thÆ° má»¥c master náº¿u chÆ°a cÃ³
    os.makedirs(MASTER_FOLDER, exist_ok=True)
    
    # TÃ¬m táº¥t cáº£ cÃ¡c file Ä‘Ã£ lÃ m sáº¡ch (cÃ³ háº­u tá»‘ _cleaned_)
    all_cleaned_files = glob.glob(os.path.join(CLEANED_FOLDER, "*_cleaned_*.csv"))
    
    if not all_cleaned_files:
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u sáº¡ch nÃ o trong {CLEANED_FOLDER}!")
        print(f"   HÃ£y cháº¡y 'python preprocessing/cleaning.py' trÆ°á»›c.")
        return
    
    print(f"ðŸ”„ Báº¯t Ä‘áº§u tá»•ng há»£p {len(all_cleaned_files)} file dá»¯ liá»‡u Ä‘Ã£ lÃ m sáº¡ch...")
    
    list_df = []
    for filename in all_cleaned_files:
        try:
            df = pd.read_csv(filename, encoding='utf-8-sig')
            
            # Kiá»ƒm tra schema
            required_cols = ['brand', 'model', 'year', 'price', 'mileage', 'fuel', 
                           'location', 'color', 'source', 'crawl_date']
            missing_cols = [col for col in required_cols if col not in df.columns]
            
            if missing_cols:
                print(f"   âš ï¸ File {os.path.basename(filename)} thiáº¿u cá»™t: {missing_cols}")
                continue
            
            # Äáº£m báº£o kiá»ƒu dá»¯ liá»‡u Ä‘Ãºng
            df['price'] = pd.to_numeric(df['price'], errors='coerce').astype('Int64')
            df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')
            df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce').astype('Int64')
            
            # Loáº¡i bá» cÃ¡c dÃ²ng cÃ³ giÃ¡ trá»‹ null á»Ÿ cÃ¡c trÆ°á»ng quan trá»ng
            df = df.dropna(subset=['price', 'year'])
            
            list_df.append(df)
            print(f"   âœ… ÄÃ£ náº¡p: {os.path.basename(filename)} ({len(df):,} dÃ²ng)")
            
        except Exception as e:
            print(f"   âŒ Lá»—i khi Ä‘á»c {filename}: {e}")
    
    if not list_df:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u há»£p lá»‡ Ä‘á»ƒ tá»•ng há»£p.")
        return
    
    # Gá»™p táº¥t cáº£ DataFrames
    print(f"\nðŸ“Š Äang gá»™p {len(list_df)} file...")
    master_df = pd.concat(list_df, ignore_index=True)
    
    print(f"   -> Tá»•ng sá»‘ dÃ²ng trÆ°á»›c khi deduplication: {len(master_df):,}")
    
    # Loáº¡i bá» trÃ¹ng láº·p (Deduplication)
    # TrÃ¡nh trÆ°á»ng há»£p má»™t xe Ä‘Äƒng trÃªn nhiá»u trang web bá»‹ tÃ­nh trÃ¹ng
    # Sá»­ dá»¥ng brand, model, year, price, mileage Ä‘á»ƒ xÃ¡c Ä‘á»‹nh trÃ¹ng láº·p
    before_count = len(master_df)
    
    # LÃ m sáº¡ch dá»¯ liá»‡u trÆ°á»›c khi deduplication
    master_df['brand'] = master_df['brand'].str.strip()
    master_df['model'] = master_df['model'].str.strip()
    
    # Deduplication: loáº¡i bá» cÃ¡c dÃ²ng trÃ¹ng láº·p
    # Giá»¯ láº¡i dÃ²ng Ä‘áº§u tiÃªn khi cÃ³ trÃ¹ng
    master_df = master_df.drop_duplicates(
        subset=['brand', 'model', 'year', 'price', 'mileage'],
        keep='first'
    )
    
    after_count = len(master_df)
    removed_duplicates = before_count - after_count
    
    # Sáº¯p xáº¿p theo nÄƒm vÃ  giÃ¡ (Ä‘á»ƒ dá»… xem)
    master_df = master_df.sort_values(['year', 'price'], ascending=[False, True])
    
    # Reset index
    master_df = master_df.reset_index(drop=True)
    
    # Äáº£m báº£o cÃ¡c cá»™t theo Ä‘Ãºng thá»© tá»± schema
    schema_cols = ['brand', 'model', 'year', 'price', 'mileage', 'fuel', 
                  'location', 'color', 'source', 'crawl_date']
    master_df = master_df[schema_cols]
    
    # Äáº·t tÃªn file cÃ³ timestamp Ä‘á»ƒ phÃ¢n biá»‡t cÃ¡c láº§n tá»•ng há»£p
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    output_filename = f"master_dataset_all_{timestamp}.csv"
    output_path = os.path.join(MASTER_FOLDER, output_filename)
    
    # LÆ°u file vÃ o má»¥c master
    master_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    # --- THá»NG KÃŠ ---
    print("\n" + "="*60)
    print(f"âœ… Tá»”NG Há»¢P THÃ€NH CÃ”NG!")
    print(f"ðŸ“Š Sá»‘ lÆ°á»£ng ban Ä‘áº§u: {before_count:,} dÃ²ng")
    print(f"ðŸ§¹ ÄÃ£ loáº¡i bá» trÃ¹ng láº·p: {removed_duplicates:,} dÃ²ng")
    print(f"ðŸ“Š Sá»‘ lÆ°á»£ng sau khi deduplication: {after_count:,} dÃ²ng")
    print(f"ðŸ’¾ File lÆ°u táº¡i: {output_path}")
    print("="*60)
    
    # Thá»‘ng kÃª theo source
    print("\n--- THá»NG KÃŠ THEO NGUá»’N Dá»® LIá»†U ---")
    source_stats = master_df['source'].value_counts()
    print(source_stats.to_string())
    
    # Thá»‘ng kÃª theo brand (Top 10)
    print("\n--- THá»NG KÃŠ THEO HÃƒNG XE (Top 10) ---")
    brand_stats = master_df['brand'].value_counts().head(10)
    print(brand_stats.to_string())
    
    # Thá»‘ng kÃª theo nÄƒm
    print("\n--- THá»NG KÃŠ THEO NÄ‚M Sáº¢N XUáº¤T ---")
    year_stats = master_df['year'].value_counts().sort_index(ascending=False).head(10)
    print(year_stats.to_string())
    
    # Thá»‘ng kÃª giÃ¡
    print("\n--- THá»NG KÃŠ GIÃ XE ---")
    print(f"   GiÃ¡ tháº¥p nháº¥t: {master_df['price'].min():,} VNÄ")
    print(f"   GiÃ¡ cao nháº¥t: {master_df['price'].max():,} VNÄ")
    print(f"   GiÃ¡ trung bÃ¬nh: {master_df['price'].mean():,.0f} VNÄ")
    print(f"   GiÃ¡ trung vá»‹: {master_df['price'].median():,.0f} VNÄ")
    
    # Hiá»ƒn thá»‹ máº«u dá»¯ liá»‡u
    print("\n--- MáºªU Dá»® LIá»†U MASTER (10 dÃ²ng Ä‘áº§u) ---")
    print(master_df.head(10).to_string())


=======
from sqlalchemy import create_engine, types

# ======================================================
# CONFIG
# ======================================================
CLEANED_FOLDER = "data/cleaned"
MASTER_FOLDER = "data/master"
DB_NAME = "car_project_db.sqlite"

REQUIRED_COLUMNS = [
    'brand', 'model', 'year', 'price', 'mileage',
    'fuel', 'location', 'color', 'source', 'crawl_date'
]

# ======================================================
# MAIN FUNCTION
# ======================================================
def aggregate_master_data():
    """
    Pipeline tá»•ng há»£p dá»¯ liá»‡u cuá»‘i:
    - Äá»c dá»¯ liá»‡u sáº¡ch
    - Validate schema
    - Chuáº©n hÃ³a dá»¯ liá»‡u
    - Lá»c trÃ¹ng, lá»c rÃ¡c
    - Táº¡o ID
    - LÆ°u CSV + SQLite
    """

    os.makedirs(MASTER_FOLDER, exist_ok=True)

    # --------------------------------------------------
    # 1. LOAD FILE CLEANED
    # --------------------------------------------------
    cleaned_files = glob.glob(os.path.join(CLEANED_FOLDER, "*_cleaned_*.csv"))

    if not cleaned_files:
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file cleaned trong {CLEANED_FOLDER}")
        return

    print(f"ðŸ”„ Äang náº¡p {len(cleaned_files)} file dá»¯ liá»‡u sáº¡ch...")

    dfs = []
    for file in cleaned_files:
        try:
            df = pd.read_csv(file, encoding="utf-8-sig")
            df.columns = df.columns.str.strip()

            # Validate schema
            missing_cols = set(REQUIRED_COLUMNS) - set(df.columns)
            if missing_cols:
                print(f"âŒ Bá» qua {os.path.basename(file)} (thiáº¿u cá»™t {missing_cols})")
                continue

            # Ã‰p kiá»ƒu dá»¯ liá»‡u
            df['price'] = pd.to_numeric(df['price'], errors='coerce')
            df['year'] = pd.to_numeric(df['year'], errors='coerce')
            df['mileage'] = pd.to_numeric(df['mileage'], errors='coerce')

            # Bá» dÃ²ng thiáº¿u dá»¯ liá»‡u quan trá»ng
            df.dropna(subset=['brand', 'price', 'year'], inplace=True)

            dfs.append(df)
            print(f"   âœ… {os.path.basename(file)}: {len(df):,} dÃ²ng")

        except Exception as e:
            print(f"   âŒ Lá»—i Ä‘á»c {file}: {e}")

    if not dfs:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u há»£p lá»‡ Ä‘á»ƒ tá»•ng há»£p.")
        return

    # --------------------------------------------------
    # 2. MERGE & DEDUPLICATION
    # --------------------------------------------------
    master_df = pd.concat(dfs, ignore_index=True)

    # Chuáº©n hÃ³a text
    for col in ['brand', 'model', 'fuel', 'color', 'location']:
        master_df[col] = master_df[col].astype(str).str.strip().str.title()

    # Lá»c trÃ¹ng
    before = len(master_df)
    master_df.drop_duplicates(
        subset=['brand', 'model', 'year', 'price', 'mileage'],
        keep='first',
        inplace=True
    )
    after = len(master_df)

    print(f"ðŸ§¹ Lá»c trÃ¹ng: {before:,} â†’ {after:,}")

    # --------------------------------------------------
    # 3. DATA STANDARDIZATION
    # --------------------------------------------------
    # Chuáº©n hÃ³a nhiÃªn liá»‡u
    fuel_map = {
        'XÄƒng': 'XÄƒng', 'Gasoline': 'XÄƒng', 'Petrol': 'XÄƒng',
        'Dáº§u': 'Dáº§u', 'Diesel': 'Dáº§u',
        'Äiá»‡n': 'Äiá»‡n', 'Electric': 'Äiá»‡n', 'Ev': 'Äiá»‡n',
        'Hybrid': 'Hybrid', 'Lai': 'Hybrid'
    }
    master_df['fuel'] = master_df['fuel'].map(fuel_map).fillna(master_df['fuel'])

    # Chuáº©n hÃ³a mÃ u
    def normalize_color(c):
        c = str(c).lower()
        if 'tráº¯ng' in c: return 'Tráº¯ng'
        if 'Ä‘en' in c: return 'Äen'
        if 'Ä‘á»' in c: return 'Äá»'
        if 'báº¡c' in c: return 'Báº¡c'
        if 'xÃ¡m' in c or 'ghi' in c: return 'XÃ¡m'
        if 'xanh' in c: return 'Xanh'
        if 'nÃ¢u' in c: return 'NÃ¢u'
        if 'vÃ ng' in c or 'cÃ¡t' in c: return 'VÃ ng'
        return 'KhÃ¡c'

    master_df['color_group'] = master_df['color'].apply(normalize_color)

    # Lá»c outlier
    current_year = datetime.now().year
    master_df = master_df[
        (master_df['year'] >= 1990) &
        (master_df['year'] <= current_year + 1) &
        (master_df['price'] >= 20_000_000)
    ]

    # --------------------------------------------------
    # 4. SORT & CREATE ID
    # --------------------------------------------------
    master_df.sort_values(
        by=['year', 'price'],
        ascending=[False, True],
        inplace=True
    )
    master_df.reset_index(drop=True, inplace=True)

    master_df.insert(0, 'id', master_df.index + 1)

    # --------------------------------------------------
    # 5. SELECT FINAL COLUMNS
    # --------------------------------------------------
    final_columns = [
        'id', 'brand', 'model', 'year', 'price', 'mileage',
        'fuel', 'location', 'color', 'color_group',
        'source', 'url', 'crawl_date'
    ]
    final_columns = [c for c in final_columns if c in master_df.columns]
    master_df = master_df[final_columns]

    # --------------------------------------------------
    # 6. SAVE CSV
    # --------------------------------------------------
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    csv_path = os.path.join(
        MASTER_FOLDER,
        f"master_dataset_final_{timestamp}.csv"
    )
    master_df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"ðŸ’¾ ÄÃ£ lÆ°u CSV: {csv_path}")

    # --------------------------------------------------
    # 7. SAVE SQLITE
    # --------------------------------------------------
    db_path = os.path.join(MASTER_FOLDER, DB_NAME)
    engine = create_engine(f"sqlite:///{os.path.abspath(db_path)}")

    master_df.to_sql(
        'cars',
        con=engine,
        if_exists='replace',
        index=False,
        dtype={
            'id': types.Integer(),
            'price': types.BigInteger(),
            'year': types.Integer(),
            'mileage': types.Integer()
        }
    )

    print(f"ðŸ—„ï¸  ÄÃ£ lÆ°u SQLite DB: {db_path}")

    # --------------------------------------------------
    # 8. SUMMARY
    # --------------------------------------------------
    print("\n" + "=" * 60)
    print("âœ… HOÃ€N Táº¤T PIPELINE MASTER DATA")
    print(f"ðŸ“Š Tá»•ng sá»‘ xe sáº¡ch: {len(master_df):,}")
    print("ðŸ”‹ PhÃ¢n bá»‘ nhiÃªn liá»‡u:")
    print(master_df['fuel'].value_counts())
    print("=" * 60)


# ======================================================
# RUN
# ======================================================
>>>>>>> daca89c9e2d6901ba83017287808cf9dcda97f35
if __name__ == "__main__":
    aggregate_master_data()
