import pandas as pd
import glob
import os
import re
from datetime import datetime

# ==============================================================================
# 1. C√ÅC H√ÄM TR√çCH XU·∫§T (EXTRACTORS)
# ==============================================================================

def clean_price(price_raw):
    """
    X·ª≠ l√Ω gi√° ti·ªÅn t·ª´ text sang s·ªë nguy√™n (VNƒê)
    H·ªó tr·ª£: 't·ªâ', 't·ª∑', 'tri·ªáu', 'VNƒê', 'ƒë·ªìng'
    
    Returns:
        int: Gi√° ti·ªÅn t√≠nh b·∫±ng VNƒê, ho·∫∑c None n·∫øu kh√¥ng parse ƒë∆∞·ª£c
    """
    if pd.isna(price_raw): 
        return None
    
    p_str = str(price_raw).lower().strip()
    
    # Lo·∫°i b·ªè c√°c tr∆∞·ªùng h·ª£p kh√¥ng c√≥ gi√°
    if any(keyword in p_str for keyword in ['li√™n h·ªá', 'th·ªèa thu·∫≠n', 'gi√°', 'call', 'contact']):
        if 'tri·ªáu' not in p_str and 't·ª∑' not in p_str and 't·ªâ' not in p_str:
            return None
    
    # Chu·∫©n h√≥a: thay 't·ªâ' th√†nh 't·ª∑'
    p_str = p_str.replace('t·ªâ', 't·ª∑')
    # Lo·∫°i b·ªè d·∫•u ch·∫•m, ph·∫©y
    p_str = p_str.replace('.', '').replace(',', '').replace(' ', '')
    
    try:
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p: "4 T·ª∑ 279 Tri·ªáu"
        if 't·ª∑' in p_str and 'tri·ªáu' in p_str:
            parts = p_str.split('t·ª∑')
            ty_match = re.search(r'(\d+)', parts[0])
            trieu_match = re.search(r'(\d+)', parts[1])
            
            ty = int(ty_match.group(1)) if ty_match else 0
            trieu = int(trieu_match.group(1)) if trieu_match else 0
            
            return int(ty * 1_000_000_000 + trieu * 1_000_000)
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ch·ªâ c√≥ "T·ª∑"
        elif 't·ª∑' in p_str:
            match = re.search(r'(\d+)', p_str)
            if match:
                ty = int(match.group(1))
                return int(ty * 1_000_000_000)
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ch·ªâ c√≥ "Tri·ªáu"
        elif 'tri·ªáu' in p_str:
            match = re.search(r'(\d+)', p_str)
            if match:
                trieu = int(match.group(1))
                return int(trieu * 1_000_000)
        
        # X·ª≠ l√Ω s·ªë thu·∫ßn (ƒë√£ l√† VNƒê)
        else:
            # T√¨m t·∫•t c·∫£ s·ªë trong chu·ªói, l·∫•y s·ªë l·ªõn nh·∫•t
            numbers = re.findall(r'\d+', p_str)
            if numbers:
                # L·∫•y s·ªë l·ªõn nh·∫•t (th∆∞·ªùng l√† gi√°)
                max_num = max(numbers, key=len)
                return int(max_num)
        
        return None
    except Exception:
        return None

BRAND_MAPPING = {
    'land rover': 'Land Rover', 'range rover': 'Land Rover',
    'mercedes-benz': 'Mercedes-Benz', 'mercedes benz': 'Mercedes-Benz', 
    'mercedes': 'Mercedes-Benz', 'merc': 'Mercedes-Benz', 'mec': 'Mercedes-Benz',
    'bmw': 'BMW', 'audi': 'Audi', 'lexus': 'Lexus', 'porsche': 'Porsche',
    'vinfast': 'VinFast', 'vin fast': 'VinFast',
    'toyota': 'Toyota', 'honda': 'Honda', 'hyundai': 'Hyundai', 'kia': 'Kia',
    'mazda': 'Mazda', 'ford': 'Ford', 'mitsubishi': 'Mitsubishi', 'nissan': 'Nissan',
    'suzuki': 'Suzuki', 'chevrolet': 'Chevrolet', 'peugeot': 'Peugeot',
    'volkswagen': 'Volkswagen', 'vw': 'Volkswagen', 'subaru': 'Subaru',
    'isuzu': 'Isuzu', 'volvo': 'Volvo', 'mini': 'Mini', 'jeep': 'Jeep',
    'mg': 'MG', 'jaguar': 'Jaguar', 'bentley': 'Bentley', 'rolls royce': 'Rolls-Royce',
    'ferrari': 'Ferrari', 'lamborghini': 'Lamborghini', 'maserati': 'Maserati',
    'tesla': 'Tesla', 'byd': 'BYD', 'wuling': 'Wuling'
}

# C√°c Model xe c√≥ t√™n gh√©p 2 t·ª´ 
MULTI_WORD_MODELS = [
    # --- 1. TOYOTA (Huy·ªÅn tho·∫°i gi·ªØ gi√°) ---
    'corolla altis', 'corolla cross', 'land cruiser', 'land cruiser prado', 
    'fj cruiser', 'urban cruiser', 'yaris cross', 'hilux', 'innova', 
    'fortuner', 'alphard', 'veloz', 'avanza', 'wigo', 'rush', 'raize',
    'hiace', 'previa', 'zace', # Zace l√† tr√πm xe c≈©

    # --- 2. HYUNDAI (Xe H√†n qu·ªëc d√¢n) ---
    'grand i10', 'i10', 'i20', 'i30', 'santa fe', 'tucson', 'accent', 
    'elantra', 'sonata', 'creta', 'venue', 'custin', 'palisade', 'stargazer', 
    'kona', 'getz', 'click', 'starex', 'terracan', 'galloper', 'genesis', 'veloster',

    # --- 3. KIA (Ph·ªï bi·∫øn) ---
    'morning', 'new morning', 'soluto', 'seltos', 'sonet', 'sorento', 
    'carnival', 'sedona', 'cerato', 'k3', 'k5', 'optima', 'rondo', 'carens', 
    'sportage', 'rio', 'spectra', 'cd5', 'pride', # Xe t·∫≠p l√°i huy·ªÅn tho·∫°i

    # --- 4. MAZDA (D√≤ng CX v√† BT) ---
    'cx 3', 'cx 30', 'cx 5', 'cx 8', 'cx 9', 'bt 50', 'bt-50', 
    'mazda 2', 'mazda 3', 'mazda 6', 'premacy', # Premacy ƒë·ªùi c≈©

    # --- 5. FORD (Vua b√°n t·∫£i & SUV) ---
    'ranger', 'ranger raptor', 'everest', 'explorer', 'territory', 'ecosport', 
    'transit', 'tourneo', 'focus', 'fiesta', 'mondeo', 'escape', 'laser', # Laser ch·∫°y r·∫•t b·ªÅn

    # --- 6. HONDA ---
    'cr v', 'hr v', 'br v', 'wr v', 'zr v', 'city', 'civic', 'accord', 
    'brio', 'jazz', 'odyssey', 'stream',

    # --- 7. MITSUBISHI ---
    'pajero', 'pajero sport', 'xpander', 'xpander cross', 'outlander', 'outlander sport',
    'triton', 'attrage', 'mirage', 'grandis', 'jolie', 'zinger', 'lancer', 'lancer gala',

    # --- 8. CHEVROLET & DAEWOO (Th·ªã tr∆∞·ªùng xe c·ªè gi√° r·∫ª) ---
    'cruze', 'aveo', 'spark', 'spark van', 'captiva', 'orlando', 'colorado', 'trailblazer',
    'lacetti', 'lacetti cdx', 'lacetti se', 'gentra', 'gentra x', 
    'matiz', 'lanos', 'nubira', 'magnus', 'leganza', # Daewoo c≈©

    # --- 9. SUZUKI ---
    'xl7', 'ertiga', 'swift', 'ciaz', 'jimny', 'vitara', 'grand vitara', 
    'blind van', 'carry', 'wagon',

    # --- 10. NISSAN ---
    'navara', 'terra', 'x trail', 'x-trail', 'almera', 'sunny', 'teana', 'kicks', 
    'tiida', 'grand livina', 'livina', 'bluebird',

    # --- 11. VINFAST ---
    'vf 3', 'vf 5', 'vf 6', 'vf 7', 'vf 8', 'vf 9', 'vf e34', 
    'lux a', 'lux a2.0', 'lux sa', 'lux sa2.0', 'fadil', 'president',

    # --- 12. MERCEDES-BENZ (D√≤ng Class & G) ---
    'c class', 'e class', 's class', 'a class', 'glc', 'gle', 'gla', 'glb', 'gls', 'glk', 
    'maybach', 'v class', 'g class', 'amg', 'sprinter', # Sprinter xe 16 ch·ªó

    # --- 13. BMW ---
    '3 series', '5 series', '7 series', 'x1', 'x3', 'x4', 'x5', 'x6', 'x7', 
    '320i', '325i', '520i', '523i', '528i', # C√°c d√≤ng s·ªë ph·ªï bi·∫øn

    # --- 14. ISUZU ---
    'd max', 'mu x', 'hilander', 'trooper',

    # --- 15. KH√ÅC (Subaru, Peugeot, MG...) ---
    'forester', 'outback', # Subaru
    '3008', '5008', '2008', '408', 'traveller', # Peugeot
    'zs', 'hs', 'rx5', 'mg5', # MG
    'beijing x7', # Xe T√†u hot
]

def extract_year_smart(row):
    """
    T√¨m nƒÉm s·∫£n xu·∫•t t·ª´ title v√† info_raw
    ∆Øu ti√™n t√¨m trong title tr∆∞·ªõc
    
    Returns:
        int: NƒÉm s·∫£n xu·∫•t (YYYY), ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    # 1. T√¨m trong title (th∆∞·ªùng c√≥ d·∫°ng: "2014 - Mazda CX5...")
    title = str(row.get('title', ''))
    year_match = re.search(r'\b(19|20)\d{2}\b', title)
    if year_match:
        year = int(year_match.group(0))
        # Validate: nƒÉm h·ª£p l√Ω t·ª´ 1990 ƒë·∫øn nƒÉm hi·ªán t·∫°i + 1
        current_year = datetime.now().year
        if 1990 <= year <= current_year + 1:
            return year
    
    # 2. T√¨m trong info_raw
    info = str(row.get('info_raw', ''))
    year_match = re.search(r'\b(19|20)\d{2}\b', info)
    if year_match:
        year = int(year_match.group(0))
        current_year = datetime.now().year
        if 1990 <= year <= current_year + 1:
            return year
    
    return None


def extract_brand_model_smart(title, source='bonbanh'):
    """
    T√°ch Brand v√† Model th√¥ng minh (H·ªó tr·ª£ 3 ngu·ªìn: bonbanh, otocomvn, chotot)
    """
    # 1. Ki·ªÉm tra d·ªØ li·ªáu r·ªóng
    if pd.isna(title) or str(title).strip() == "":
        return "Other", "Other"
    
    # 2. Ti·ªÅn x·ª≠ l√Ω chung (X√≥a nƒÉm, ƒë∆∞a v·ªÅ ch·ªØ th∆∞·ªùng)
    raw_title = str(title).lower().strip()
    clean_text = re.sub(r'\b(19|20)\d{2}\b', ' ', raw_title) # X√≥a nƒÉm 19xx-20xx

    # 3. X·ª≠ l√Ω ri√™ng cho t·ª´ng ngu·ªìn (Source-specific logic)
    if source == 'bonbanh':
        # Bonbanh: Th∆∞·ªùng c√≥ "Xe c≈©", "Xe m·ªõi", v√† gi√° sau d·∫•u "-"
        clean_text = clean_text.replace('xe c≈©', '').replace('xe m·ªõi', '')
        
        # X√≥a d·∫•u g·∫°ch ngang ƒë·∫ßu c√¢u (do x√≥a nƒÉm ƒë·ªÉ l·∫°i)
        clean_text = clean_text.strip()
        if clean_text.startswith('-') or clean_text.startswith('‚Äì'):
            clean_text = clean_text[1:].strip()
            
        # C·∫Øt b·ªè ph·∫ßn gi√°/ƒë·ªãa ƒëi·ªÉm sau d·∫•u g·∫°ch ngang (n·∫øu c√≥)
        if ' - ' in clean_text:
            parts = clean_text.split(' - ')
            # Logic: N·∫øu ph·∫ßn ƒë·∫ßu d√†i (ch·ª©a t√™n xe) th√¨ l·∫•y, n·∫øu ng·∫Øn qu√° (m√£ tin) th√¨ l·∫•y ph·∫ßn sau
            if len(parts[0].strip()) > 3: 
                clean_text = parts[0]
            elif len(parts) > 1:
                clean_text = parts[1]

    elif source == 'chotot':
        # Chotot: Nhi·ªÅu t·ª´ r√°c c·∫£m th√°n
        stopwords = ['c·∫ßn b√°n', 'b√°n g·∫•p', 'thanh l√Ω', 'gi√° r·∫ª', 'xe nh√†', 'ch√≠nh ch·ªß', 'gia ƒë√¨nh', 'b√°n xe']
        for word in stopwords:
            clean_text = clean_text.replace(word, '')
            
    elif source == 'otocomvn':
        # Oto.com.vn: Kh√° s·∫°ch, ch·ªâ c·∫ßn b·ªè ch·ªØ "b√°n xe"
        clean_text = clean_text.replace('b√°n xe', '')

    # 4. L√†m s·∫°ch k√Ω t·ª± ƒë·∫∑c bi·ªát
    clean_text = re.sub(r'[^\w\s]', ' ', clean_text)
    clean_text = " ".join(clean_text.split())

    # 5. T√¨m H√£ng xe (Brand)
    found_brand = "Other"
    found_brand_key = ""
    
    for key in BRAND_MAPPING:
        # D√πng regex \b ƒë·ªÉ kh·ªõp ƒë√∫ng t·ª´ (vd: tr√°nh kh·ªõp "mazda" trong "amazda")
        if re.search(r'\b' + re.escape(key) + r'\b', clean_text):
            found_brand = BRAND_MAPPING[key]
            found_brand_key = key
            break 
    
    if found_brand == "Other":
        return "Other", "Other"

    # 6. T√¨m D√≤ng xe (Model)
    # X√≥a t√™n h√£ng ƒë√£ t√¨m ƒë∆∞·ª£c kh·ªèi chu·ªói ƒë·ªÉ t√¨m model trong ph·∫ßn c√≤n l·∫°i
    model_part = re.sub(r'\b' + re.escape(found_brand_key) + r'\b', '', clean_text).strip()
    found_model = "Other"
    model_tokens = model_part.split()
    
    if model_tokens:
        # ∆Øu ti√™n t√¨m model gh√©p 2 t·ª´ (VD: Land Cruiser, CX 5)
        if len(model_tokens) >= 2:
            two_words = model_tokens[0] + " " + model_tokens[1]
            two_words_norm = two_words.replace('-', ' ') # Chu·∫©n h√≥a g·∫°ch ngang
            
            if two_words_norm in MULTI_WORD_MODELS:
                found_model = two_words_norm
            # Logic ƒë·∫∑c bi·ªát cho Mercedes S Class, C Class...
            elif found_brand == 'Mercedes-Benz' and model_tokens[1] == 'class':
                found_model = model_tokens[0] + " Class"
            else:
                found_model = model_tokens[0] # L·∫•y t·ª´ ƒë·∫ßu ti√™n
        else:
            found_model = model_tokens[0] # L·∫•y t·ª´ duy nh·∫•t c√≤n l·∫°i

    # 7. Chu·∫©n h√≥a t√™n Model l·∫ßn cu·ªëi (Post-processing)
    found_model = found_model.upper()
    
    if found_model.startswith('VF'): # VF3 -> VF 3
        found_model = found_model.replace('VF', 'VF ').replace('  ', ' ').strip()
    if found_model.startswith('CX'): # CX5 -> CX 5
        found_model = found_model.replace('CX', 'CX ').replace('  ', ' ').strip()
    if 'CLASS' in found_model: # SCLASS -> S CLASS
        found_model = found_model.replace('CLASS', ' CLASS').replace('  ', ' ').strip()
        
    return found_brand, found_model.title()


def extract_mileage_smart(text):
    """
    T√¨m s·ªë km ƒë√£ ƒëi (mileage/odo)
    
    Returns:
        int: S·ªë km, ho·∫∑c 0 n·∫øu kh√¥ng t√¨m th·∫•y
    """
    if pd.isna(text):
        return 0
    
    s = str(text).lower()
    # Lo·∫°i b·ªè d·∫•u ch·∫•m, ph·∫©y trong s·ªë
    s = s.replace('.', '').replace(',', '')
    
    # T√¨m pattern: s·ªë + "km" ho·∫∑c "v km" (v√≠ d·ª•: "110,000 km" ho·∫∑c "11v km")
    patterns = [
        r'(\d+)\s*v\s*km',  # "11v km"
        r'(\d+)\s*km',       # "110000 km"
        r'ƒë√£\s*ƒëi\s*(\d+)',  # "ƒë√£ ƒëi 110000"
        r'odo[:\s]*(\d+)',   # "odo: 110000"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, s)
        if match:
            try:
                km = int(match.group(1))
                # N·∫øu l√† "v km" (v√≠ d·ª•: 11v = 110,000), nh√¢n v·ªõi 10000
                if 'v' in match.group(0).lower():
                    km = km * 10000
                return km
            except:
                continue
    
    return 0


def extract_fuel(text):
    """
    T√¨m lo·∫°i nhi√™n li·ªáu
    
    Returns:
        str: Lo·∫°i nhi√™n li·ªáu (XƒÉng, D·∫ßu, ƒêi·ªán, Hybrid, Unknown)
    """
    if pd.isna(text):
        return "Unknown"
    
    s = str(text).lower()
    
    # ∆Øu ti√™n: ƒêi·ªán > Hybrid > D·∫ßu > XƒÉng
    if any(keyword in s for keyword in ['ƒëi·ªán', 'ev', 'electric', 'pin']):
        return 'ƒêi·ªán'
    if any(keyword in s for keyword in ['hybrid', 'hev', 'phev']):
        return 'Hybrid'
    if any(keyword in s for keyword in ['d·∫ßu', 'diesel']):
        return 'D·∫ßu'
    if any(keyword in s for keyword in ['xƒÉng', 'petrol', 'gasoline', 'benzin']):
        return 'XƒÉng'
    
    return "Unknown"


def extract_color(text):
    """
    T√¨m m√†u s·∫Øc xe
    
    Returns:
        str: M√†u xe, ho·∫∑c "Unknown"
    """
    if pd.isna(text):
        return "Unknown"
    
    s = str(text).lower()
    
    colors_map = {
        'tr·∫Øng': 'Tr·∫Øng', 'trang': 'Tr·∫Øng',
        'ƒëen': 'ƒêen', 'den': 'ƒêen',
        'ƒë·ªè': 'ƒê·ªè', 'do': 'ƒê·ªè', 'red': 'ƒê·ªè',
        'b·∫°c': 'B·∫°c', 'bac': 'B·∫°c', 'silver': 'B·∫°c',
        'x√°m': 'X√°m', 'xam': 'X√°m', 'ghi': 'X√°m', 'gray': 'X√°m', 'grey': 'X√°m',
        'n√¢u': 'N√¢u', 'nau': 'N√¢u', 'brown': 'N√¢u',
        'v√†ng': 'V√†ng', 'vang': 'V√†ng', 'yellow': 'V√†ng',
        'cam': 'Cam', 'orange': 'Cam',
        'xanh': 'Xanh', 'blue': 'Xanh', 'green': 'Xanh',
        'xanh d∆∞∆°ng': 'Xanh d∆∞∆°ng', 'xanh l√°': 'Xanh l√°',
        'ƒë·ªìng': 'ƒê·ªìng', 'dong': 'ƒê·ªìng', 'copper': 'ƒê·ªìng',
        'be': 'Be', 'beige': 'Be',
        't√≠m': 'T√≠m', 'purple': 'T√≠m',
        'h·ªìng': 'H·ªìng', 'pink': 'H·ªìng'
    }
    
    for key, val in colors_map.items():
        if key in s:
            return val
    
    return "Unknown"


def extract_location_smart(text):
    """
    T√¨m T·ªânh/Th√†nh ph·ªë
    
    Returns:
        str: T√™n t·ªânh/th√†nh ph·ªë, ho·∫∑c "Kh√°c"
    """
    if pd.isna(text):
        return "Kh√°c"
    
    s = str(text).lower()
    
    # Danh s√°ch c√°c t·ªânh th√†nh ph·ªë (m·ªü r·ªông)
    cities = {
        'h√† n·ªôi': 'H√† N·ªôi', 'hanoi': 'H√† N·ªôi',
        'hcm': 'TP.HCM', 'h·ªì ch√≠ minh': 'TP.HCM', 's√†i g√≤n': 'TP.HCM', 
        'tp.hcm': 'TP.HCM', 'tp hcm': 'TP.HCM', 'ho chi minh': 'TP.HCM',
        'ƒë√† n·∫µng': 'ƒê√† N·∫µng', 'danang': 'ƒê√† N·∫µng',
        'h·∫£i ph√≤ng': 'H·∫£i Ph√≤ng', 'haiphong': 'H·∫£i Ph√≤ng',
        'c·∫ßn th∆°': 'C·∫ßn Th∆°', 'cantho': 'C·∫ßn Th∆°',
        'ngh·ªá an': 'Ngh·ªá An', 'nghe an': 'Ngh·ªá An',
        'b√¨nh d∆∞∆°ng': 'B√¨nh D∆∞∆°ng', 'binh duong': 'B√¨nh D∆∞∆°ng',
        'ƒë·ªìng nai': 'ƒê·ªìng Nai', 'dong nai': 'ƒê·ªìng Nai',
        'h∆∞ng y√™n': 'H∆∞ng Y√™n', 'hung yen': 'H∆∞ng Y√™n',
        'b√† r·ªãa': 'B√† R·ªãa - V≈©ng T√†u', 'v≈©ng t√†u': 'B√† R·ªãa - V≈©ng T√†u',
        'b√† r·ªãa v≈©ng t√†u': 'B√† R·ªãa - V≈©ng T√†u', 'br-vt': 'B√† R·ªãa - V≈©ng T√†u',
        'b·∫Øc ninh': 'B·∫Øc Ninh', 'bac ninh': 'B·∫Øc Ninh',
        'h·∫£i d∆∞∆°ng': 'H·∫£i D∆∞∆°ng', 'hai duong': 'H·∫£i D∆∞∆°ng',
        'thanh h√≥a': 'Thanh H√≥a', 'thanh hoa': 'Thanh H√≥a',
        'qu·∫£ng ninh': 'Qu·∫£ng Ninh', 'quang ninh': 'Qu·∫£ng Ninh',
        'kh√°nh h√≤a': 'Kh√°nh H√≤a', 'khanh hoa': 'Kh√°nh H√≤a', 'nha trang': 'Kh√°nh H√≤a',
        'l√¢m ƒë·ªìng': 'L√¢m ƒê·ªìng', 'lam dong': 'L√¢m ƒê·ªìng', 'ƒë√† l·∫°t': 'L√¢m ƒê·ªìng', 'dalat': 'L√¢m ƒê·ªìng',
        'b√¨nh thu·∫≠n': 'B√¨nh Thu·∫≠n', 'binh thuan': 'B√¨nh Thu·∫≠n',
        'ki√™n giang': 'Ki√™n Giang', 'kien giang': 'Ki√™n Giang',
        'th√°i nguy√™n': 'Th√°i Nguy√™n', 'thai nguyen': 'Th√°i Nguy√™n',
        'an giang': 'An Giang',
        'long an': 'Long An',
        'ti·ªÅn giang': 'Ti·ªÅn Giang', 'tien giang': 'Ti·ªÅn Giang',
        'b·∫øn tre': 'B·∫øn Tre', 'ben tre': 'B·∫øn Tre',
        'vƒ©nh long': 'Vƒ©nh Long', 'vinh long': 'Vƒ©nh Long',
        'c√† mau': 'C√† Mau', 'ca mau': 'C√† Mau'
    }
    
    # T√¨m trong text
    for key, val in cities.items():
        if key in s:
            return val
    
    return "Kh√°c"


# ==============================================================================
# 2. PIPELINE CH√çNH
# ==============================================================================

def run_cleaning():
    """
    Pipeline ch√≠nh ƒë·ªÉ l√†m s·∫°ch d·ªØ li·ªáu t·ª´ data/raw
    ƒê·ªçc file raw m·ªõi nh·∫•t, extract c√°c tr∆∞·ªùng theo schema, v√† l∆∞u v√†o data/cleaned
    """
    RAW_FOLDER = 'data/raw'
    CLEANED_FOLDER = 'data/cleaned'
    os.makedirs(CLEANED_FOLDER, exist_ok=True)
    
    # T√¨m file raw m·ªõi nh·∫•t
    files = glob.glob(os.path.join(RAW_FOLDER, "*.csv"))
    if not files:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu raw n√†o!")
        return
    
    # L·∫•y file m·ªõi nh·∫•t
    latest_file = max(files, key=os.path.getctime)
    print(f"üîÑ ƒêang x·ª≠ l√Ω file: {os.path.basename(latest_file)}")
    
    try:
        # ƒê·ªçc file (∆Øu ti√™n utf-8-sig)
        try:
            df = pd.read_csv(latest_file, encoding='utf-8-sig')
        except:
            print("   ‚ö†Ô∏è Encoding m·∫∑c ƒë·ªãnh l·ªói, th·ª≠ UTF-8...")
            df = pd.read_csv(latest_file, encoding='utf-8')
        
        print(f"   -> T·ªïng s·ªë d√≤ng raw: {len(df):,}")
        print(f"   -> C√°c c·ªôt c√≥ s·∫µn: {list(df.columns)}")
        
        # Chu·∫©n h√≥a t√™n c·ªôt
        column_mapping = {
            'gia_xe': 'price_raw',
            'tieu_de': 'title',
            'thong_tin': 'info_raw',
            'gia': 'price_raw',
            'link': 'url'
        }
        df.rename(columns=column_mapping, inplace=True)
        
        # ƒê·∫£m b·∫£o c√≥ c√°c c·ªôt c·∫ßn thi·∫øt
        required_raw_cols = ['title', 'price_raw', 'info_raw']
        missing_cols = [col for col in required_raw_cols if col not in df.columns]
        if missing_cols:
            print(f"   ‚ùå Thi·∫øu c√°c c·ªôt: {missing_cols}")
            return
        
        # G·ªôp text ƒë·ªÉ t√¨m ki·∫øm t·ªët h∆°n
        df['full_text'] = df['title'].fillna('') + ' | ' + df['info_raw'].fillna('')
        
        print("\n   üîç ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu...")
        
        # --- TR√çCH XU·∫§T D·ªÆ LI·ªÜU THEO SCHEMA ---
        
        # 1. Price (b·∫Øt bu·ªôc)
        print("      -> Tr√≠ch xu·∫•t gi√°...")
        df['price'] = df['price_raw'].apply(clean_price)
        
        # 2. Year (b·∫Øt bu·ªôc)
        print("      -> Tr√≠ch xu·∫•t nƒÉm s·∫£n xu·∫•t...")
        df['year'] = df.apply(extract_year_smart, axis=1)
        
        # 3. Brand & Model
        print("      -> Tr√≠ch xu·∫•t h√£ng v√† d√≤ng xe...")
        df[['brand', 'model']] = df['title'].apply(
            lambda x: pd.Series(extract_brand_model_smart(x))
        )
        
        # 4. Mileage
        print("      -> Tr√≠ch xu·∫•t s·ªë km...")
        df['mileage'] = df['full_text'].apply(extract_mileage_smart)
        
        # 5. Fuel
        print("      -> Tr√≠ch xu·∫•t lo·∫°i nhi√™n li·ªáu...")
        df['fuel'] = df['full_text'].apply(extract_fuel)
        
        # 6. Location
        print("      -> Tr√≠ch xu·∫•t ƒë·ªãa ƒëi·ªÉm...")
        df['location'] = df['full_text'].apply(extract_location_smart)
        
        # 7. Color
        print("      -> Tr√≠ch xu·∫•t m√†u s·∫Øc...")
        df['color'] = df['full_text'].apply(extract_color)
        
        # 8. Source & Crawl_date (gi·ªØ nguy√™n t·ª´ raw data)
        if 'source' not in df.columns:
            df['source'] = df.get('source', 'bonbanh')
        if 'crawl_date' not in df.columns:
            df['crawl_date'] = df.get('crawl_date', datetime.now().strftime("%Y-%m-%d"))
        
        # --- L·ªåC D·ªÆ LI·ªÜU ---
        print("\n   üßπ ƒêang l·ªçc d·ªØ li·ªáu...")
        
        # L·ªçc c√°c d√≤ng kh√¥ng c√≥ price ho·∫∑c year (b·∫Øt bu·ªôc)
        before_filter = len(df)
        df_clean = df.dropna(subset=['price', 'year'])
        after_filter = len(df_clean)
        print(f"      -> ƒê√£ lo·∫°i b·ªè {before_filter - after_filter} d√≤ng thi·∫øu price/year")
        
        # L·ªçc theo logic nghi·ªáp v·ª•
        # - Gi√° > 50 tri·ªáu (tr√°nh xe ƒë·ªì ch∆°i, ph·ª• t√πng)
        # - NƒÉm > 1990 (xe qu√° c≈©)
        # - NƒÉm <= nƒÉm hi·ªán t·∫°i + 1 (xe t∆∞∆°ng lai kh√¥ng h·ª£p l√Ω)
        current_year = datetime.now().year
        df_clean = df_clean[
            (df_clean['price'] > 50_000_000) & 
            (df_clean['year'] > 1990) & 
            (df_clean['year'] <= current_year + 1)
        ]
        after_business_filter = len(df_clean)
        print(f"      -> ƒê√£ lo·∫°i b·ªè {after_filter - after_business_filter} d√≤ng kh√¥ng h·ª£p l·ªá")
        
        # --- CHU·∫®N H√ìA KI·ªÇU D·ªÆ LI·ªÜU ---
        print("\n   üîß ƒêang chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu...")
        
        # ƒê·∫£m b·∫£o price, year, mileage l√† int
        df_clean['price'] = df_clean['price'].astype(int)
        df_clean['year'] = df_clean['year'].astype(int)
        df_clean['mileage'] = df_clean['mileage'].astype(int)

        # ƒê·∫£m b·∫£o c·ªôt url t·ªìn t·∫°i
        if 'url' not in df_clean.columns:
            # N·∫øu kh√¥ng c√≥ c·ªôt url, th·ª≠ t√¨m xem trong df g·ªëc c√≥ kh√¥ng
            if 'url' in df.columns:
                df_clean['url'] = df['url']
            else:
                # N·∫øu v·∫´n kh√¥ng c√≥, t·∫°o c·ªôt r·ªóng (ƒë·ªÉ kh√¥ng b·ªã l·ªói)
                df_clean['url'] = ""

    
        # Ch·ªçn c√°c c·ªôt theo schema
        schema_cols = ['brand', 'model', 'year', 'price', 'mileage', 'fuel', 
                      'location', 'color', 'source', 'crawl_date', 'url']
        available_cols = [c for c in schema_cols if c in df_clean.columns]
        df_final = df_clean[available_cols].copy()
        
        df_final = df_clean[schema_cols].copy()
        
        # --- L∆ØU FILE ---
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        raw_filename = os.path.basename(latest_file)
        source_name = raw_filename.split('_')[0] if '_' in raw_filename else 'bonbanh'
        
        output_filename = f"{source_name}_cleaned_{timestamp}.csv"
        output_path = os.path.join(CLEANED_FOLDER, output_filename)
        
        df_final.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        # --- TH·ªêNG K√ä ---
        print("\n" + "="*60)
        print(f"‚úÖ HO√ÄN T·∫§T!")
        print(f"üìä S·ªë l∆∞·ª£ng ban ƒë·∫ßu: {before_filter:,} d√≤ng")
        print(f"üìä S·ªë l∆∞·ª£ng sau khi l√†m s·∫°ch: {len(df_final):,} d√≤ng")
        print(f"üìÅ File k·∫øt qu·∫£: {output_filename}")
        print("="*60)
        
        # Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu
        print("\n--- M·∫™U D·ªÆ LI·ªÜU SAU KHI L√ÄM S·∫†CH ---")
        print(df_final.head(10).to_string())
        
        # Th·ªëng k√™ theo brand
        print("\n--- TH·ªêNG K√ä THEO H√ÉNG XE (Top 10) ---")
        brand_stats = df_final['brand'].value_counts().head(10)
        print(brand_stats.to_string())
        
    except Exception as e:
        print(f"‚ùå L·ªói nghi√™m tr·ªçng: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_cleaning()
