import pandas as pd
import glob
import os
import re
from datetime import datetime

# ==============================================================================
# 1. C√ÅC H√ÄM TR√çCH XU·∫§T (EXTRACTORS)
# ==============================================================================

def clean_price(price_raw):
    """
    X·ª≠ l√Ω gi√° ti·ªÅn t·ª´ text sang s·ªë nguy√™n (VNƒê)
    H·ªó tr·ª£: 't·ªâ', 't·ª∑', 'tri·ªáu', 'VNƒê', 'ƒë·ªìng'
    
    Returns:
        int: Gi√° ti·ªÅn t√≠nh b·∫±ng VNƒê, ho·∫∑c None n·∫øu kh√¥ng parse ƒë∆∞·ª£c
    """
    if pd.isna(price_raw): 
        return None
    
    p_str = str(price_raw).lower().strip()
    
    # Lo·∫°i b·ªè c√°c tr∆∞·ªùng h·ª£p kh√¥ng c√≥ gi√°
    if any(keyword in p_str for keyword in ['li√™n h·ªá', 'th·ªèa thu·∫≠n', 'gi√°', 'call', 'contact']):
        if 'tri·ªáu' not in p_str and 't·ª∑' not in p_str and 't·ªâ' not in p_str:
            return None
    
    # Chu·∫©n h√≥a: thay 't·ªâ' th√†nh 't·ª∑'
    p_str = p_str.replace('t·ªâ', 't·ª∑')
    # Lo·∫°i b·ªè d·∫•u ch·∫•m, ph·∫©y
    p_str = p_str.replace('.', '').replace(',', '').replace(' ', '')
    
    try:
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p: "4 T·ª∑ 279 Tri·ªáu"
        if 't·ª∑' in p_str and 'tri·ªáu' in p_str:
            parts = p_str.split('t·ª∑')
            ty_match = re.search(r'(\d+)', parts[0])
            trieu_match = re.search(r'(\d+)', parts[1])
            
            ty = int(ty_match.group(1)) if ty_match else 0
            trieu = int(trieu_match.group(1)) if trieu_match else 0
            
            return int(ty * 1_000_000_000 + trieu * 1_000_000)
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ch·ªâ c√≥ "T·ª∑"
        elif 't·ª∑' in p_str:
            match = re.search(r'(\d+)', p_str)
            if match:
                ty = int(match.group(1))
                return int(ty * 1_000_000_000)
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p ch·ªâ c√≥ "Tri·ªáu"
        elif 'tri·ªáu' in p_str:
            match = re.search(r'(\d+)', p_str)
            if match:
                trieu = int(match.group(1))
                return int(trieu * 1_000_000)
        
        # X·ª≠ l√Ω s·ªë thu·∫ßn (ƒë√£ l√† VNƒê)
        else:
            # T√¨m t·∫•t c·∫£ s·ªë trong chu·ªói, l·∫•y s·ªë l·ªõn nh·∫•t
            numbers = re.findall(r'\d+', p_str)
            if numbers:
                # L·∫•y s·ªë l·ªõn nh·∫•t (th∆∞·ªùng l√† gi√°)
                max_num = max(numbers, key=len)
                return int(max_num)
        
        return None
    except Exception:
        return None


def extract_year_smart(row):
    """
    T√¨m nƒÉm s·∫£n xu·∫•t t·ª´ title v√† info_raw
    ∆Øu ti√™n t√¨m trong title tr∆∞·ªõc
    
    Returns:
        int: NƒÉm s·∫£n xu·∫•t (YYYY), ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
    """
    # 1. T√¨m trong title (th∆∞·ªùng c√≥ d·∫°ng: "2014 - Mazda CX5...")
    title = str(row.get('title', ''))
    year_match = re.search(r'\b(19|20)\d{2}\b', title)
    if year_match:
        year = int(year_match.group(0))
        current_year = datetime.now().year
        if 1990 <= year <= current_year + 1:
            return year
    
    # 2. T√¨m trong info_raw
    info = str(row.get('info_raw', ''))
    year_match = re.search(r'\b(19|20)\d{2}\b', info)
    if year_match:
        year = int(year_match.group(0))
        current_year = datetime.now().year
        if 1990 <= year <= current_year + 1:
            return year
    
    return None


def extract_brand_model_smart(title):
    """
    T√°ch Brand v√† Model t·ª´ ti√™u ƒë·ªÅ
    
    V√≠ d·ª•: "2014 - Mazda CX5 2.0 AT" -> brand="Mazda", model="CX5"
    
    Returns:
        tuple: (brand, model)
    """
    if pd.isna(title):
        return "Other", "Other"
    
    # B·ªè nƒÉm v√† d·∫•u g·∫°ch ngang ·ªü ƒë·∫ßu: "2014 - " ho·∫∑c "2014-"
    clean_title = re.sub(r'^(19|20)\d{2}\s*[-‚Äì]\s*', '', str(title).strip())
    
    # B·ªè c√°c t·ª´ kh√¥ng c·∫ßn thi·∫øt ·ªü ƒë·∫ßu
    clean_title = re.sub(r'^(xe\s+(c≈©|m·ªõi|ƒë√£|s·ª≠ d·ª•ng))\s*', '', clean_title, flags=re.IGNORECASE)
    
    parts = clean_title.split()
    if not parts:
        return "Other", "Other"
    
    # Danh s√°ch h√£ng xe ph·ªï bi·∫øn (m·ªü r·ªông)
    brands_list = [
        'toyota', 'hyundai', 'kia', 'mazda', 'honda', 'ford', 'mercedes', 'bmw', 
        'audi', 'vinfast', 'mitsubishi', 'nissan', 'suzuki', 'lexus', 'porsche', 
        'land rover', 'mg', 'peugeot', 'volvo', 'subaru', 'isuzu', 'chevrolet',
        'renault', 'vw', 'volkswagen', 'mini', 'jaguar', 'infiniti', 'acura',
        'genesis', 'cadillac', 'lincoln', 'bentley', 'rolls-royce', 'maserati',
        'ferrari', 'lamborghini', 'mclaren', 'tesla', 'fiat', 'opel', 'skoda',
        'seat', 'dacia', 'geely', 'haval', 'great wall', 'chery', 'byd'
    ]
    
    brand = "Other"
    model = "Other"
    
    # T√¨m brand (th∆∞·ªùng l√† t·ª´ ƒë·∫ßu ti√™n ho·∫∑c t·ª´ ƒë·∫ßu ti√™n + t·ª´ th·ª© hai)
    found_brand = False
    
    # Th·ª≠ 2 t·ª´ ƒë·∫ßu (cho "Land Rover", "Great Wall")
    if len(parts) >= 2:
        two_words = f"{parts[0].lower()} {parts[1].lower()}"
        for b in brands_list:
            if b in two_words:
                if b == 'bmw' or b == 'mg' or b == 'vw':
                    brand = b.upper()
                elif b == 'land rover':
                    brand = 'Land Rover'
                elif b == 'great wall':
                    brand = 'Great Wall'
                else:
                    brand = b.title()
                found_brand = True
                # Model l√† t·ª´ th·ª© 3 tr·ªü ƒëi
                if len(parts) > 2:
                    model = ' '.join(parts[2:4])  # L·∫•y 2 t·ª´ ƒë·∫ßu c·ªßa model
                break
    
    # N·∫øu ch∆∞a t√¨m th·∫•y, th·ª≠ 1 t·ª´ ƒë·∫ßu
    if not found_brand and len(parts) > 0:
        first_word = parts[0].lower()
        for b in brands_list:
            if b in first_word or first_word in b:
                if b == 'bmw' or b == 'mg' or b == 'vw':
                    brand = b.upper()
                else:
                    brand = b.title()
                found_brand = True
                # Model l√† t·ª´ th·ª© 2 tr·ªü ƒëi
                if len(parts) > 1:
                    model = parts[1]  # L·∫•y t·ª´ ƒë·∫ßu ti√™n c·ªßa model
                break
    
    # N·∫øu v·∫´n ch∆∞a t√¨m th·∫•y, l·∫•y t·ª´ ƒë·∫ßu ti√™n l√†m brand (heuristic)
    if not found_brand and len(parts) > 0:
        brand = parts[0].title()
        if len(parts) > 1:
            model = parts[1]
    
    # L√†m s·∫°ch model (b·ªè s·ªë, k√Ω t·ª± ƒë·∫∑c bi·ªát kh√¥ng c·∫ßn thi·∫øt)
    if model != "Other":
        model = re.sub(r'^\d+\.?\d*\s*', '', model)  # B·ªè s·ªë ·ªü ƒë·∫ßu
        model = model.strip()
    
    return brand, model


def extract_mileage_smart(text):
    """
    T√¨m s·ªë km ƒë√£ ƒëi (mileage/odo)
    
    Returns:
        int: S·ªë km, ho·∫∑c 0 n·∫øu kh√¥ng t√¨m th·∫•y
    """
    if pd.isna(text):
        return 0
    
    s = str(text).lower()
    # Lo·∫°i b·ªè d·∫•u ch·∫•m, ph·∫©y trong s·ªë
    s = s.replace('.', '').replace(',', '')
    
    # T√¨m pattern: s·ªë + "km" ho·∫∑c "v km" (v√≠ d·ª•: "110,000 km" ho·∫∑c "11v km")
    patterns = [
        r'(\d+)\s*v\s*km',  # "11v km"
        r'(\d+)\s*km',       # "110000 km"
        r'ƒë√£\s*ƒëi\s*(\d+)',  # "ƒë√£ ƒëi 110000"
        r'odo[:\s]*(\d+)',   # "odo: 110000"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, s)
        if match:
            try:
                km = int(match.group(1))
                # N·∫øu l√† "v km" (v√≠ d·ª•: 11v = 110,000), nh√¢n v·ªõi 10000
                if 'v' in match.group(0).lower():
                    km = km * 10000
                return km
            except:
                continue
    
    return 0


def extract_fuel(text):
    """
    T√¨m lo·∫°i nhi√™n li·ªáu
    
    Returns:
        str: Lo·∫°i nhi√™n li·ªáu (XƒÉng, D·∫ßu, ƒêi·ªán, Hybrid, Unknown)
    """
    if pd.isna(text):
        return "Unknown"
    
    s = str(text).lower()
    
    # ∆Øu ti√™n: ƒêi·ªán > Hybrid > D·∫ßu > XƒÉng
    if any(keyword in s for keyword in ['ƒëi·ªán', 'ev', 'electric', 'pin']):
        return 'ƒêi·ªán'
    if any(keyword in s for keyword in ['hybrid', 'hev', 'phev']):
        return 'Hybrid'
    if any(keyword in s for keyword in ['d·∫ßu', 'diesel']):
        return 'D·∫ßu'
    if any(keyword in s for keyword in ['xƒÉng', 'petrol', 'gasoline', 'benzin']):
        return 'XƒÉng'
    
    return "Unknown"


def extract_color(text):
    """
    T√¨m m√†u s·∫Øc xe
    
    Returns:
        str: M√†u xe, ho·∫∑c "Unknown"
    """
    if pd.isna(text):
        return "Unknown"
    
    s = str(text).lower()
    
    colors_map = {
        'tr·∫Øng': 'Tr·∫Øng', 'trang': 'Tr·∫Øng',
        'ƒëen': 'ƒêen', 'den': 'ƒêen',
        'ƒë·ªè': 'ƒê·ªè', 'do': 'ƒê·ªè', 'red': 'ƒê·ªè',
        'b·∫°c': 'B·∫°c', 'bac': 'B·∫°c', 'silver': 'B·∫°c',
        'x√°m': 'X√°m', 'xam': 'X√°m', 'ghi': 'X√°m', 'gray': 'X√°m', 'grey': 'X√°m',
        'n√¢u': 'N√¢u', 'nau': 'N√¢u', 'brown': 'N√¢u',
        'v√†ng': 'V√†ng', 'vang': 'V√†ng', 'yellow': 'V√†ng',
        'cam': 'Cam', 'orange': 'Cam',
        'xanh': 'Xanh', 'blue': 'Xanh', 'green': 'Xanh',
        'xanh d∆∞∆°ng': 'Xanh d∆∞∆°ng', 'xanh l√°': 'Xanh l√°',
        'ƒë·ªìng': 'ƒê·ªìng', 'dong': 'ƒê·ªìng', 'copper': 'ƒê·ªìng',
        'be': 'Be', 'beige': 'Be',
        't√≠m': 'T√≠m', 'purple': 'T√≠m',
        'h·ªìng': 'H·ªìng', 'pink': 'H·ªìng'
    }
    
    for key, val in colors_map.items():
        if key in s:
            return val
    
    return "Unknown"


def extract_location_smart(text):
    """
    T√¨m T·ªânh/Th√†nh ph·ªë
    
    Returns:
        str: T√™n t·ªânh/th√†nh ph·ªë, ho·∫∑c "Kh√°c"
    """
    if pd.isna(text):
        return "Kh√°c"
    
    s = str(text).lower()
    
    # Danh s√°ch c√°c t·ªânh th√†nh ph·ªë (m·ªü r·ªông)
    cities = {
        'h√† n·ªôi': 'H√† N·ªôi', 'hanoi': 'H√† N·ªôi',
        'hcm': 'TP.HCM', 'h·ªì ch√≠ minh': 'TP.HCM', 's√†i g√≤n': 'TP.HCM', 
        'tp.hcm': 'TP.HCM', 'tp hcm': 'TP.HCM', 'ho chi minh': 'TP.HCM',
        'ƒë√† n·∫µng': 'ƒê√† N·∫µng', 'danang': 'ƒê√† N·∫µng',
        'h·∫£i ph√≤ng': 'H·∫£i Ph√≤ng', 'haiphong': 'H·∫£i Ph√≤ng',
        'c·∫ßn th∆°': 'C·∫ßn Th∆°', 'cantho': 'C·∫ßn Th∆°',
        'ngh·ªá an': 'Ngh·ªá An', 'nghe an': 'Ngh·ªá An',
        'b√¨nh d∆∞∆°ng': 'B√¨nh D∆∞∆°ng', 'binh duong': 'B√¨nh D∆∞∆°ng',
        'ƒë·ªìng nai': 'ƒê·ªìng Nai', 'dong nai': 'ƒê·ªìng Nai',
        'h∆∞ng y√™n': 'H∆∞ng Y√™n', 'hung yen': 'H∆∞ng Y√™n',
        'b√† r·ªãa': 'B√† R·ªãa - V≈©ng T√†u', 'v≈©ng t√†u': 'B√† R·ªãa - V≈©ng T√†u',
        'b√† r·ªãa v≈©ng t√†u': 'B√† R·ªãa - V≈©ng T√†u', 'br-vt': 'B√† R·ªãa - V≈©ng T√†u',
        'b·∫Øc ninh': 'B·∫Øc Ninh', 'bac ninh': 'B·∫Øc Ninh',
        'h·∫£i d∆∞∆°ng': 'H·∫£i D∆∞∆°ng', 'hai duong': 'H·∫£i D∆∞∆°ng',
        'thanh h√≥a': 'Thanh H√≥a', 'thanh hoa': 'Thanh H√≥a',
        'qu·∫£ng ninh': 'Qu·∫£ng Ninh', 'quang ninh': 'Qu·∫£ng Ninh',
        'kh√°nh h√≤a': 'Kh√°nh H√≤a', 'khanh hoa': 'Kh√°nh H√≤a', 'nha trang': 'Kh√°nh H√≤a',
        'l√¢m ƒë·ªìng': 'L√¢m ƒê·ªìng', 'lam dong': 'L√¢m ƒê·ªìng', 'ƒë√† l·∫°t': 'L√¢m ƒê·ªìng', 'dalat': 'L√¢m ƒê·ªìng',
        'b√¨nh thu·∫≠n': 'B√¨nh Thu·∫≠n', 'binh thuan': 'B√¨nh Thu·∫≠n',
        'ki√™n giang': 'Ki√™n Giang', 'kien giang': 'Ki√™n Giang',
        'th√°i nguy√™n': 'Th√°i Nguy√™n', 'thai nguyen': 'Th√°i Nguy√™n',
        'an giang': 'An Giang',
        'long an': 'Long An',
        'ti·ªÅn giang': 'Ti·ªÅn Giang', 'tien giang': 'Ti·ªÅn Giang',
        'b·∫øn tre': 'B·∫øn Tre', 'ben tre': 'B·∫øn Tre',
        'vƒ©nh long': 'Vƒ©nh Long', 'vinh long': 'Vƒ©nh Long',
        'c√† mau': 'C√† Mau', 'ca mau': 'C√† Mau'
    }
    
    # T√¨m trong text
    for key, val in cities.items():
        if key in s:
            return val
    
    return "Kh√°c"


# ==============================================================================
# 2. PIPELINE CH√çNH
# ==============================================================================

def run_cleaning():
    """
    Pipeline ch√≠nh ƒë·ªÉ l√†m s·∫°ch d·ªØ li·ªáu t·ª´ data/raw
    ƒê·ªçc file raw m·ªõi nh·∫•t, extract c√°c tr∆∞·ªùng theo schema, v√† l∆∞u v√†o data/cleaned
    """
    RAW_FOLDER = 'data/raw'
    CLEANED_FOLDER = 'data/cleaned'
    os.makedirs(CLEANED_FOLDER, exist_ok=True)
    
    # T√¨m file raw m·ªõi nh·∫•t
    files = glob.glob(os.path.join(RAW_FOLDER, "*.csv"))
    if not files:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu raw n√†o!")
        return
    
    # L·∫•y file m·ªõi nh·∫•t
    latest_file = max(files, key=os.path.getctime)
    print(f"üîÑ ƒêang x·ª≠ l√Ω file: {os.path.basename(latest_file)}")
    
    try:
        # ƒê·ªçc file (∆Øu ti√™n utf-8-sig)
        try:
            df = pd.read_csv(latest_file, encoding='utf-8-sig')
        except:
            print("   ‚ö†Ô∏è Encoding m·∫∑c ƒë·ªãnh l·ªói, th·ª≠ UTF-8...")
            df = pd.read_csv(latest_file, encoding='utf-8')
        
        print(f"   -> T·ªïng s·ªë d√≤ng raw: {len(df):,}")
        print(f"   -> C√°c c·ªôt c√≥ s·∫µn: {list(df.columns)}")
        
        # Chu·∫©n h√≥a t√™n c·ªôt (n·∫øu c·∫ßn)
        column_mapping = {
            'gia_xe': 'price_raw',
            'tieu_de': 'title',
            'thong_tin': 'info_raw',
            'gia': 'price_raw'
        }
        df.rename(columns=column_mapping, inplace=True)
        
        # ƒê·∫£m b·∫£o c√≥ c√°c c·ªôt c·∫ßn thi·∫øt
        required_raw_cols = ['title', 'price_raw', 'info_raw']
        missing_cols = [col for col in required_raw_cols if col not in df.columns]
        if missing_cols:
            print(f"   ‚ùå Thi·∫øu c√°c c·ªôt: {missing_cols}")
            return
        
        # G·ªôp text ƒë·ªÉ t√¨m ki·∫øm t·ªët h∆°n
        df['full_text'] = df['title'].fillna('') + ' | ' + df['info_raw'].fillna('')
        
        print("\n   üîç ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu...")
        
        # --- TR√çCH XU·∫§T D·ªÆ LI·ªÜU THEO SCHEMA ---
        
        # 1. Price (b·∫Øt bu·ªôc)
        print("      -> Tr√≠ch xu·∫•t gi√°...")
        df['price'] = df['price_raw'].apply(clean_price)
        
        # 2. Year (b·∫Øt bu·ªôc)
        print("      -> Tr√≠ch xu·∫•t nƒÉm s·∫£n xu·∫•t...")
        df['year'] = df.apply(extract_year_smart, axis=1)
        
        # 3. Brand & Model
        print("      -> Tr√≠ch xu·∫•t h√£ng v√† d√≤ng xe...")
        df[['brand', 'model']] = df['title'].apply(
            lambda x: pd.Series(extract_brand_model_smart(x))
        )
        
        # 4. Mileage
        print("      -> Tr√≠ch xu·∫•t s·ªë km...")
        df['mileage'] = df['full_text'].apply(extract_mileage_smart)
        
        # 5. Fuel
        print("      -> Tr√≠ch xu·∫•t lo·∫°i nhi√™n li·ªáu...")
        df['fuel'] = df['full_text'].apply(extract_fuel)
        
        # 6. Location
        print("      -> Tr√≠ch xu·∫•t ƒë·ªãa ƒëi·ªÉm...")
        df['location'] = df['full_text'].apply(extract_location_smart)
        
        # 7. Color
        print("      -> Tr√≠ch xu·∫•t m√†u s·∫Øc...")
        df['color'] = df['full_text'].apply(extract_color)
        
        # 8. Source & Crawl_date (gi·ªØ nguy√™n t·ª´ raw data)
        if 'source' not in df.columns:
            df['source'] = df.get('source', 'bonbanh')
        if 'crawl_date' not in df.columns:
            df['crawl_date'] = df.get('crawl_date', datetime.now().strftime("%Y-%m-%d"))
        
        # --- L·ªåC D·ªÆ LI·ªÜU ---
        print("\n   üßπ ƒêang l·ªçc d·ªØ li·ªáu...")
        
        # L·ªçc c√°c d√≤ng kh√¥ng c√≥ price ho·∫∑c year (b·∫Øt bu·ªôc)
        before_filter = len(df)
        df_clean = df.dropna(subset=['price', 'year'])
        after_filter = len(df_clean)
        print(f"      -> ƒê√£ lo·∫°i b·ªè {before_filter - after_filter} d√≤ng thi·∫øu price/year")
        
        # L·ªçc theo logic nghi·ªáp v·ª•
        # - Gi√° > 50 tri·ªáu (tr√°nh xe ƒë·ªì ch∆°i, ph·ª• t√πng)
        # - NƒÉm > 1990 (xe qu√° c≈©)
        # - NƒÉm <= nƒÉm hi·ªán t·∫°i + 1 (xe t∆∞∆°ng lai kh√¥ng h·ª£p l√Ω)
        current_year = datetime.now().year
        df_clean = df_clean[
            (df_clean['price'] > 50_000_000) & 
            (df_clean['year'] > 1990) & 
            (df_clean['year'] <= current_year + 1)
        ]
        after_business_filter = len(df_clean)
        print(f"      -> ƒê√£ lo·∫°i b·ªè {after_filter - after_business_filter} d√≤ng kh√¥ng h·ª£p l·ªá")
        
        # --- CHU·∫®N H√ìA KI·ªÇU D·ªÆ LI·ªÜU ---
        print("\n   üîß ƒêang chu·∫©n h√≥a ki·ªÉu d·ªØ li·ªáu...")
        
        # ƒê·∫£m b·∫£o price, year, mileage l√† int
        df_clean['price'] = df_clean['price'].astype(int)
        df_clean['year'] = df_clean['year'].astype(int)
        df_clean['mileage'] = df_clean['mileage'].astype(int)
        
        # Ch·ªçn c√°c c·ªôt theo schema
        schema_cols = ['brand', 'model', 'year', 'price', 'mileage', 'fuel', 
                      'location', 'color', 'source', 'crawl_date']
        
        df_final = df_clean[schema_cols].copy()
        
        # --- L∆ØU FILE ---
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        raw_filename = os.path.basename(latest_file)
        source_name = raw_filename.split('_')[0] if '_' in raw_filename else 'bonbanh'
        
        output_filename = f"{source_name}_cleaned_{timestamp}.csv"
        output_path = os.path.join(CLEANED_FOLDER, output_filename)
        
        df_final.to_csv(output_path, index=False, encoding='utf-8-sig')
        
        # --- TH·ªêNG K√ä ---
        print("\n" + "="*60)
        print(f"‚úÖ HO√ÄN T·∫§T!")
        print(f"üìä S·ªë l∆∞·ª£ng ban ƒë·∫ßu: {before_filter:,} d√≤ng")
        print(f"üìä S·ªë l∆∞·ª£ng sau khi l√†m s·∫°ch: {len(df_final):,} d√≤ng")
        print(f"üìÅ File k·∫øt qu·∫£: {output_filename}")
        print("="*60)
        
        # Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu
        print("\n--- M·∫™U D·ªÆ LI·ªÜU SAU KHI L√ÄM S·∫†CH ---")
        print(df_final.head(10).to_string())
        
        # Th·ªëng k√™ theo brand
        print("\n--- TH·ªêNG K√ä THEO H√ÉNG XE (Top 10) ---")
        brand_stats = df_final['brand'].value_counts().head(10)
        print(brand_stats.to_string())
        
    except Exception as e:
        print(f"‚ùå L·ªói nghi√™m tr·ªçng: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_cleaning()
